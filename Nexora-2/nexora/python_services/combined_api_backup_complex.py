#!/usr/bin/env python3
"""
Nexora Credit Score API - Supabase Database Only
This version uses only Supabase database, no in-memory storage
"""

from fastapi import FastAPI, File, UploadFile, HTTPException, Depends, Header, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
import shutil
import os
import json
import asyncio
import jwt
import bcrypt
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta
from invoice_2 import main as extract_invoice_main
from credit_score import main as calculate_credit_score_main
from dotenv import load_dotenv
from supabase import create_client, Client
import uvicorn
from pathlib import Path
from uuid import uuid4

# Load environment variables
load_dotenv()

# Supabase configuration
SUPABASE_URL = os.getenv("SUPABASE_URL", "https://eecbqzvcnwrkcxgwjxlt.supabase.co")
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImVlY2JxenZjbndya2N4Z3dqeGx0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTU0Mjk1NjEsImV4cCI6MjA3MTAwNTU2MX0.CkhFT-6LKFg6NCc9WIiZRjNQ7VGVX6nJmoOxjMVHDKs")

# Groq API configuration
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Initialize Supabase client
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    print("‚úÖ Supabase client initialized successfully")
    print(f"üìä Connected to: {SUPABASE_URL}")
except Exception as e:
    print(f"‚ùå Failed to initialize Supabase: {e}")
    raise

app = FastAPI(title="Nexora Credit Score API - Supabase", version="2.0.0")

# JWT Configuration
SECRET_KEY = os.getenv("JWT_SECRET_KEY", "dev_secret_key_please_change_in_production_12345")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

security = HTTPBearer()

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5001", "http://127.0.0.1:5001","https://nexora-2-0-5.onrender.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# ----------------- Data Models ----------------- #
class UserRegistration(BaseModel):
    email: str
    password: str
    full_name: str

class UserLogin(BaseModel):
    email: str
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str
    user_data: Dict

class LineItem(BaseModel):
    description: str
    amount: float

# ----------------- Insurance Hub Data Models ----------------- #
class InsuranceAssessmentRequest(BaseModel):
    business_type: str
    assets: Dict[str, Any] = Field(default_factory=dict, description="Key-value pairs of asset categories to their estimated values")
    workforce_size: Optional[int] = 0
    risk_concerns: List[str] = Field(default_factory=list)
    region: Optional[str] = "India"
    annual_revenue: Optional[float] = None
    preferences: Optional[Dict[str, Any]] = None  # e.g. {"focus": "employee_welfare", "budget_level": "medium"}

class InsurancePolicyCreate(BaseModel):
    business_id: int
    policy_name: str
    policy_type: str
    provider_name: Optional[str] = None
    coverage_amount: float
    premium_amount: float
    premium_range: Optional[str] = None
    legal_compliance: Optional[bool] = True
    compliance_authority: Optional[str] = "IRDAI"
    start_date: datetime
    expiry_date: datetime
    policy_number: Optional[str] = None
    coverage_details: Optional[Dict[str, Any]] = None
    exclusions: Optional[Dict[str, Any]] = None
    optional_addons: Optional[Dict[str, Any]] = None

class InsurancePolicyUpdate(BaseModel):
    coverage_amount: Optional[float] = None
    premium_amount: Optional[float] = None
    premium_range: Optional[str] = None
    status: Optional[str] = None
    expiry_date: Optional[datetime] = None
    start_date: Optional[datetime] = None
    policy_number: Optional[str] = None
    document_url: Optional[str] = None
    coverage_details: Optional[Dict[str, Any]] = None
    exclusions: Optional[Dict[str, Any]] = None
    optional_addons: Optional[Dict[str, Any]] = None

class AdvisorConnectRequest(BaseModel):
    topic: str
    details: Optional[str] = None
    urgency: Optional[str] = "normal"  # 'low', 'normal', 'high'
    preferred_contact: Optional[str] = "email"

# ----------------- Helper Functions ----------------- #
def hash_password(password: str) -> str:
    """Hash a password using bcrypt"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def verify_password(password: str, hashed: str) -> bool:
    """Verify a password against its hash"""
    return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """Create a JWT access token"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Get current user from JWT token"""
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Could not validate credentials")
        return user_id
    except jwt.PyJWTError:
        raise HTTPException(status_code=401, detail="Could not validate credentials")

# ----------------- Database Initialization ----------------- #
def init_database_tables():
    """Initialize database tables using raw SQL"""
    try:
        print("üîß Initializing Supabase database tables...")
        
        # Check if tables exist by querying them
        try:
            # Try to select from users table
            result = supabase.table('users').select('id').limit(1).execute()
            print("‚úÖ Users table already exists")
        except:
            print("üìã Creating users table...")
            # Table doesn't exist, it will be created via SQL schema
        
        try:
            # Try to select from invoices table  
            result = supabase.table('invoices').select('id').limit(1).execute()
            print("‚úÖ Invoices table already exists")
        except:
            print("üìã Creating invoices table...")
            # Table doesn't exist, it will be created via SQL schema
        # Optional: probe insurance tables (do not fail if missing yet)
        for tbl in ["insurance_policies", "insurance_templates", "business_risk_assessments", "policy_reminders"]:
            try:
                supabase.table(tbl).select('count').limit(1).execute()
                print(f"‚úÖ {tbl} table available")
            except Exception:
                print(f"‚ÑπÔ∏è {tbl} table not found yet (run insurance_policies_schema.sql if you need Insurance Hub)")
            
        print("‚úÖ Database initialization completed!")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Database initialization warning: {e}")
        print("üí° Please run the SQL schema in your Supabase SQL editor if tables don't exist")

# Initialize database on startup
init_database_tables()

# ----------------- API Endpoints ----------------- #

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "message": "Nexora Credit Score API - Supabase Database",
        "version": "2.0.0",
        "database": "Supabase",
        "status": "operational",
        "endpoints": {
            "register": "/register",
            "login": "/login", 
            "upload": "/upload-invoice",
            "dashboard": "/dashboard/credit-score",
            "invoices": "/user/invoices"
        }
    }

@app.post("/register", response_model=Token)
async def register_user(user: UserRegistration):
    """Register a new user in Supabase"""
    try:
        print(f"üìù Attempting to register user: {user.email}")
        
        # Check if user already exists
        existing_user = supabase.table("users").select("*").eq("email", user.email).execute()
        if existing_user.data:
            raise HTTPException(status_code=400, detail="Email already registered")
        
        # Hash password and create user
        hashed_password = hash_password(user.password)
        user_data = {
            "email": user.email,
            "full_name": user.full_name,
            "password_hash": hashed_password
        }
        
        # Insert user into database
        result = supabase.table("users").insert(user_data).execute()
        if not result.data:
            raise HTTPException(status_code=500, detail="Failed to create user")
        
        created_user = result.data[0]
        print(f"‚úÖ User registered successfully: {created_user['email']} (ID: {created_user['id']})")
        
        # Create access token
        access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = create_access_token(
            data={"sub": str(created_user["id"])}, expires_delta=access_token_expires
        )
        
        return {
            "access_token": access_token,
            "token_type": "bearer",
            "user_data": {
                "id": str(created_user["id"]),
                "email": created_user["email"],
                "full_name": created_user["full_name"]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Registration error: {e}")
        raise HTTPException(status_code=500, detail=f"Registration failed: {str(e)}")

@app.post("/login", response_model=Token)
async def login_user(user: UserLogin):
    """Login user with Supabase database"""
    try:
        print(f"üîê Attempting login for user: {user.email}")
        
        # Get user from database
        result = supabase.table("users").select("*").eq("email", user.email).execute()
        if not result.data:
            raise HTTPException(status_code=401, detail="Invalid credentials")
        
        db_user = result.data[0]
        
        # Verify password
        if not verify_password(user.password, db_user["password_hash"]):
            raise HTTPException(status_code=401, detail="Invalid credentials")
        
        print(f"‚úÖ Login successful for user: {db_user['email']} (ID: {db_user['id']})")
        
        # Create access token
        access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = create_access_token(
            data={"sub": str(db_user["id"])}, expires_delta=access_token_expires
        )
        
        return {
            "access_token": access_token,
            "token_type": "bearer",
            "user_data": {
                "id": str(db_user["id"]),
                "email": db_user["email"],
                "full_name": db_user["full_name"]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Login error: {e}")
        raise HTTPException(status_code=500, detail=f"Login failed: {str(e)}")

@app.post("/upload-invoice")
async def process_invoice(
    file: UploadFile = File(...),
    current_user: str = Depends(get_current_user)
):
    """Process uploaded invoice and store in Supabase with credit score"""
    try:
        print(f"üìÑ Processing invoice upload for user: {current_user}")
        
        # Save uploaded file temporarily
        temp_file_path = f"temp_invoice_{current_user}_{datetime.now().timestamp()}.{file.filename.split('.')[-1]}"
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # Extract invoice details
        print("üîç Extracting invoice details...")
        invoice_result_raw = await asyncio.to_thread(extract_invoice_main, temp_file_path, GROQ_API_KEY)
        
        # The invoice_2.py returns a JSON string, so we need to parse it
        try:
            if isinstance(invoice_result_raw, str):
                invoice_result = json.loads(invoice_result_raw)
            else:
                invoice_result = invoice_result_raw
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parsing invoice result JSON: {e}")
            raise HTTPException(status_code=400, detail="Invoice extraction returned invalid JSON")
        
        if not invoice_result.get("invoice_details"):
            raise HTTPException(status_code=400, detail=f"Invoice extraction failed: No invoice details found")
        
        invoice_details = invoice_result["invoice_details"]
        print(f"‚úÖ Invoice extracted: {invoice_details.get('invoice_number', 'Unknown')}")

        # --- Sanitize and truncate string fields to fit DB constraints ---
        def _truncate(val, max_len):
            if val is None:
                return None
            s = str(val)
            return s[:max_len]

        # Log original lengths for debugging
        debug_lengths = {
            'invoice_number_len': len(str(invoice_details.get('invoice_number', ''))),
            'client_len': len(str(invoice_details.get('client', ''))),
            'payment_terms_len': len(str(invoice_details.get('payment_terms', ''))),
            'industry_len': len(str(invoice_details.get('industry', ''))),
            'currency_len': len(str(invoice_details.get('currency', '')))
        }
        print(f"üîé Field lengths before truncation: {debug_lengths}")

        # Apply truncation according to supabase_schema.sql
        invoice_number = _truncate(invoice_details.get('invoice_number', 'INV-UNKNOWN'), 255)
        client = _truncate(invoice_details.get('client', 'Unknown Client'), 255)
        payment_terms = _truncate(invoice_details.get('payment_terms', 'Not specified'), 255)
        industry = _truncate(invoice_details.get('industry', 'General'), 255)
        # Currency limited to 20 chars; keep only first 10 non-space chars typical codes
        raw_currency = _truncate(invoice_details.get('currency', 'INR'), 20)
        # Normalize currency to uppercase short code if it's long descriptive text
        if len(raw_currency) > 10:
            # Extract potential code (letters only) from beginning
            import re as _re
            match = _re.search(r"[A-Za-z]{3,5}", raw_currency.upper())
            currency = match.group(0) if match else raw_currency[:10].upper()
        else:
            currency = raw_currency.upper()
        print(f"üí± Normalized currency: '{raw_currency}' -> '{currency}'")
        
        # Get all existing invoices for user to calculate historical data & detect duplicates
        existing_invoices = supabase.table('invoices').select('*').eq('user_id', int(current_user)).execute()
        total_invoices = len(existing_invoices.data) if existing_invoices.data else 0

        # Duplicate detection (idempotent behavior)
        # We'll sanitize the invoice number first (same logic used later) to compare apples-to-apples
        raw_invoice_number = invoice_details.get("invoice_number", "INV-UNKNOWN")
        sanitized_invoice_number = str(raw_invoice_number)[:255]
        duplicate_invoice = None
        if existing_invoices.data:
            for inv in existing_invoices.data:
                if inv.get('invoice_number') == sanitized_invoice_number:
                    duplicate_invoice = inv
                    break

        if duplicate_invoice:
            print("‚ö†Ô∏è Duplicate invoice upload detected; returning existing record without re-processing credit score")
            # Clean up temp file early
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
            return {
                "success": True,
                "message": "Invoice already processed previously; returning existing record",
                "invoice_details": {
                    "id": duplicate_invoice["id"],
                    "invoice_number": duplicate_invoice["invoice_number"],
                    "client": duplicate_invoice["client"],
                    "total_amount": duplicate_invoice["total_amount"],
                    "credit_score": duplicate_invoice.get("credit_score")
                },
                "credit_score_analysis": duplicate_invoice.get("credit_score_data", {}),
                "historical_summary": {
                    "total_historical_invoices": total_invoices,
                    "total_amount_all_invoices": sum([inv['total_amount'] for inv in existing_invoices.data]) if existing_invoices.data else 0
                },
                "duplicate": True
            }
        
        # Calculate total amounts for credit score calculation
        total_amount = sum([inv['total_amount'] for inv in existing_invoices.data]) if existing_invoices.data else 0
        invoice_total = float(invoice_details.get('total_amount', 0))
        total_amount += invoice_total
        
        # Calculate credit score for this invoice
        print("üìä Calculating credit score...")
        credit_score_data = {
            "no_of_invoices": total_invoices + 1,
            "total_amount": total_amount,
            "total_amount_pending": invoice_total,  # New invoice is pending
            "total_amount_paid": total_amount - invoice_total,
            "tax": float(invoice_details.get('tax_amount', 0)),
            "extra_charges": float(invoice_details.get('extra_charges', 0)),
            "payment_completion_rate": 0.8,  # Default assumption
            "paid_to_pending_ratio": 0.6     # Default assumption
        }
        
        credit_score_result = await asyncio.to_thread(calculate_credit_score_main, credit_score_data, GROQ_API_KEY)
        # The credit_score_main returns a JSON string; parse if needed
        try:
            if isinstance(credit_score_result, str):
                credit_score_result_parsed = json.loads(credit_score_result)
            else:
                credit_score_result_parsed = credit_score_result
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parsing credit score JSON: {e}")
            credit_score_result_parsed = {"credit_score_analysis": {}}

        individual_credit_score = (
            credit_score_result_parsed
                .get('credit_score_analysis', {})
                .get('final_weighted_credit_score', 0)
        )
        
        print(f"‚úÖ Individual credit score calculated: {individual_credit_score}")
        
        # Prepare invoice data for database
        invoice_db_data = {
            "user_id": int(current_user),
            "invoice_number": invoice_number,
            "client": client,
            "date": invoice_details.get("date"),
            "payment_terms": payment_terms,
            "industry": industry,
            "total_amount": invoice_total,
            "currency": currency,
            "tax_amount": float(invoice_details.get("tax_amount", 0)),
            "extra_charges": float(invoice_details.get("extra_charges", 0)),
            "line_items": invoice_details.get("line_items", []),
            "status": "pending",
            "credit_score": individual_credit_score,
            "credit_score_data": credit_score_result_parsed.get('credit_score_analysis', {})
        }
        print("üßπ Sanitized invoice payload prepared for DB insert")
        
        # Insert invoice into database
        print("üíæ Saving invoice to Supabase...")
        try:
            result = supabase.table("invoices").insert(invoice_db_data).execute()
            if not result.data:
                raise HTTPException(status_code=500, detail="Failed to save invoice to database")
        except Exception as insert_error:
            # Handle duplicate race condition (if another request inserted same invoice between detection & insert)
            if 'duplicate key value' in str(insert_error) or '23505' in str(insert_error):
                print("‚ö†Ô∏è Duplicate detected at insert time (race). Fetching existing record.")
                existing = supabase.table('invoices').select('*').eq('user_id', int(current_user)).eq('invoice_number', invoice_db_data['invoice_number']).limit(1).execute()
                if existing.data:
                    saved_invoice = existing.data[0]
                    # Clean up temp
                    if os.path.exists(temp_file_path):
                        os.remove(temp_file_path)
                    return {
                        "success": True,
                        "message": "Invoice already existed; returning existing record",
                        "invoice_details": {
                            "id": saved_invoice["id"],
                            "invoice_number": saved_invoice["invoice_number"],
                            "client": saved_invoice["client"],
                            "total_amount": saved_invoice["total_amount"],
                            "credit_score": saved_invoice.get("credit_score")
                        },
                        "credit_score_analysis": saved_invoice.get("credit_score_data", {}),
                        "historical_summary": {
                            "total_historical_invoices": total_invoices,
                            "total_amount_all_invoices": sum([inv['total_amount'] for inv in existing_invoices.data]) if existing_invoices.data else 0
                        },
                        "duplicate": True
                    }
            # Re-raise if not handled duplicate
            raise
        
        saved_invoice = result.data[0]
        print(f"‚úÖ Invoice saved to database with ID: {saved_invoice['id']}")
        
        # Clean up temp file
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        
        return {
            "success": True,
            "message": "Invoice processed and saved successfully",
            "invoice_details": {
                "id": saved_invoice["id"],
                "invoice_number": saved_invoice["invoice_number"],
                "client": saved_invoice["client"],
                "total_amount": saved_invoice["total_amount"],
                "credit_score": saved_invoice["credit_score"]
            },
            "credit_score_analysis": credit_score_result_parsed.get('credit_score_analysis', {}),
            "historical_summary": {
                "total_historical_invoices": total_invoices + 1,
                "total_amount_all_invoices": total_amount
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        # Clean up temp file in case of error
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        print(f"‚ùå Invoice processing error: {e}")
        raise HTTPException(status_code=500, detail=f"Invoice processing failed: {str(e)}")

@app.post("/process-invoice")
async def upload_invoice_alias(
    file: UploadFile = File(...),
    current_user: str = Depends(get_current_user)
):
    """Alias endpoint for frontend compatibility - same as /upload-invoice"""
    return await process_invoice(file, current_user)

@app.post("/calculate-credit-score")
async def calculate_credit_score_alias(credit_data: dict):
    """Alias endpoint for frontend compatibility - calculate credit score (no auth required for testing)"""
    try:
        print("üìä Calculating credit score...")
        result = await asyncio.to_thread(calculate_credit_score_main, credit_data, GROQ_API_KEY)
        print("‚úÖ Credit score calculated")
        return result
    except Exception as e:
        print(f"‚ùå Credit score calculation error: {e}")
        raise HTTPException(status_code=500, detail=f"Credit score calculation failed: {str(e)}")

@app.get("/dashboard/credit-score")
async def get_dashboard_credit_score(current_user: str = Depends(get_current_user)):
    """Get dashboard credit score calculated as mean of all invoice credit scores from Supabase"""
    try:
        print(f"üìä Fetching dashboard credit score for user: {current_user}")
        
        # Get all invoices with credit scores for the user
        result = supabase.table('invoices').select('*').eq('user_id', int(current_user)).execute()
        invoices = result.data or []
        
        if not invoices:
            return {
                "credit_score": 0,
                "category": "No Data",
                "total_invoices": 0,
                "last_updated": "No invoices uploaded yet",
                "loading": False,
                "error": None
            }
        
        # Calculate mean credit score from all invoices
        credit_scores = [inv['credit_score'] for inv in invoices if inv['credit_score'] is not None]
        
        if not credit_scores:
            mean_credit_score = 0
            category = "No Data"
        else:
            mean_credit_score = sum(credit_scores) / len(credit_scores)
            # Determine category based on mean score
            if mean_credit_score >= 80:
                category = "Excellent"
            elif mean_credit_score >= 70:
                category = "Good"
            elif mean_credit_score >= 60:
                category = "Fair"
            else:
                category = "Poor"
        
        print(f"‚úÖ Dashboard credit score calculated from Supabase: {mean_credit_score:.1f} ({category})")
        
        return {
            "credit_score": round(mean_credit_score, 1),
            "category": category,
            "total_invoices": len(invoices),
            "last_updated": datetime.now().strftime("%m/%d/%Y"),
            "loading": False,
            "error": None,
            "debug_info": {
                "individual_scores": credit_scores,
                "mean_calculation": f"{sum(credit_scores)}/{len(credit_scores)}" if credit_scores else "0/0",
                "invoice_count": len(invoices),
                "database": "Supabase"
            }
        }
        
    except Exception as e:
        print(f"‚ùå Dashboard credit score error: {e}")
        return {
            "credit_score": 0,
            "category": "Error",
            "total_invoices": 0,
            "last_updated": "Error occurred",
            "loading": False,
            "error": str(e)
        }

@app.get("/user/invoices")
async def get_user_invoices(current_user: str = Depends(get_current_user)):
    """Get all invoices for the current user from Supabase"""
    try:
        print(f"üìã Fetching invoices for user: {current_user}")
        
        # Get all invoices for the user, ordered by creation date
        result = supabase.table('invoices').select('*').eq('user_id', int(current_user)).order('created_at', desc=True).execute()
        invoices = result.data or []
        
        print(f"‚úÖ Retrieved {len(invoices)} invoices from Supabase")
        
        return {
            "success": True,
            "invoices": invoices,
            "total_count": len(invoices)
        }
        
    except Exception as e:
        print(f"‚ùå Error fetching user invoices: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch invoices: {str(e)}")

@app.post("/calculate-single-invoice-credit-score")
async def calculate_single_invoice_credit_score(credit_data: dict):
    """Calculate credit score for a single invoice (utility endpoint)"""
    try:
        print("üìä Calculating single invoice credit score...")
        result = await asyncio.to_thread(calculate_credit_score_main, credit_data, GROQ_API_KEY)
        print("‚úÖ Single invoice credit score calculated")
        return result
    except Exception as e:
        print(f"‚ùå Single invoice credit score calculation error: {e}")
        raise HTTPException(status_code=500, detail=f"Credit score calculation failed: {str(e)}")

@app.get("/get-business")
async def get_business(current_user: str = Depends(get_current_user)):
    """Get business information for the current user"""
    try:
        print(f"üè¢ Fetching business info for user: {current_user}")
        
        # Get user data which might include business info
        result = supabase.table('users').select('*').eq('id', int(current_user)).execute()
        user_data = result.data[0] if result.data else {}
        
        # Mock business data structure - in production this would be a separate businesses table
        business_data = {
            "business_name": user_data.get("full_name", "Business Name"),
            "industry": "Technology",
            "revenue": 1000000,
            "employees": 50,
            "location": "Mumbai, India",
            "established_year": 2020
        }
        
        return {"success": True, "business": business_data}
    except Exception as e:
        print(f"‚ùå Error fetching business info: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch business info: {str(e)}")

@app.post("/register-business")
async def register_business(business: dict, current_user: str = Depends(get_current_user)):
    """Register or update business details for the current user.
    Currently stores data inside the users table (mock) until a dedicated businesses table usage is added.
    """
    try:
        print(f"üè¢ Saving business info for user: {current_user}")
        # Basic validation
        if not business.get("business_name"):
            raise HTTPException(status_code=400, detail="Business name is required")

        # Upsert strategy: store limited business fields in users table's full_name (or later extend schema)
        # Placeholder: we just acknowledge receipt
        return {"success": True, "message": "Business details received", "business": business}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error registering business: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to register business: {str(e)}")

def generate_policy_content(policy_type: str, business: dict, language: str = "en") -> str:
    """
    Generate realistic policy content based on business details and policy type.
    This creates comprehensive, legally-informed policies tailored to the specific business.
    Supports multiple languages: en, hi, es, fr
    """
    business_name = business.get('business_name', 'Your Business')
    business_type = business.get('business_type', 'business')
    industry = business.get('industry', 'general')
    location_country = business.get('location_country', 'India')
    website_url = business.get('website_url', f'www.{business_name.lower().replace(" ", "")}.com')
    has_online_presence = business.get('has_online_presence', False)
    processes_payments = business.get('processes_payments', False)
    uses_cookies = business.get('uses_cookies', False)
    collects_personal_data = business.get('collects_personal_data', True)
    target_audience = business.get('target_audience', 'B2C')
    data_retention_period = business.get('data_retention_period', 365)
    
    current_date = datetime.now().strftime("%B %d, %Y")
    
    # Language-specific translations
    translations = {
        'en': {
            'privacy_policy': 'PRIVACY POLICY',
            'effective_date': 'Effective Date',
            'last_updated': 'Last Updated',
            'introduction': 'INTRODUCTION',
            'welcome_text': f'Welcome to **{business_name}**',
            'info_we_collect': 'INFORMATION WE COLLECT',
            'personal_info': 'Personal Information',
            'how_we_use': 'HOW WE USE YOUR INFORMATION',
            'data_security': 'DATA SECURITY',
            'contact_info': 'CONTACT INFORMATION'
        },
        'hi': {
            'privacy_policy': '‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø',
            'effective_date': '‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§§‡§ø‡§•‡§ø',
            'last_updated': '‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§¨‡§æ‡§∞ ‡§Ö‡§™‡§°‡•á‡§ü',
            'introduction': '‡§™‡§∞‡§ø‡§ö‡§Ø',
            'welcome_text': f'**{business_name}** ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à',
            'info_we_collect': '‡§π‡§Æ ‡§ú‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï‡§§‡•ç‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç',
            'personal_info': '‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä',
            'how_we_use': '‡§π‡§Æ ‡§Ü‡§™‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç',
            'data_security': '‡§°‡•á‡§ü‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ',
            'contact_info': '‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä'
        },
        'es': {
            'privacy_policy': 'POL√çTICA DE PRIVACIDAD',
            'effective_date': 'Fecha de vigencia',
            'last_updated': '√öltima actualizaci√≥n',
            'introduction': 'INTRODUCCI√ìN',
            'welcome_text': f'Bienvenido a **{business_name}**',
            'info_we_collect': 'INFORMACI√ìN QUE RECOPILAMOS',
            'personal_info': 'Informaci√≥n Personal',
            'how_we_use': 'C√ìMO USAMOS SU INFORMACI√ìN',
            'data_security': 'SEGURIDAD DE DATOS',
            'contact_info': 'INFORMACI√ìN DE CONTACTO'
        },
        'fr': {
            'privacy_policy': 'POLITIQUE DE CONFIDENTIALIT√â',
            'effective_date': 'Date d\'entr√©e en vigueur',
            'last_updated': 'Derni√®re mise √† jour',
            'introduction': 'INTRODUCTION',
            'welcome_text': f'Bienvenue chez **{business_name}**',
            'info_we_collect': 'INFORMATIONS QUE NOUS COLLECTONS',
            'personal_info': 'Informations Personnelles',
            'how_we_use': 'COMMENT NOUS UTILISONS VOS INFORMATIONS',
            'data_security': 'S√âCURIT√â DES DONN√âES',
            'contact_info': 'INFORMATIONS DE CONTACT'
        }
    }
    
    # Get translations for the selected language, fallback to English
    t = translations.get(language, translations['en'])
    
    if policy_type == 'privacy_policy':
        if language == 'hi':  # Hindi
            return f"""# {t['privacy_policy']}

**{t['effective_date']}:** {current_date}  
**{t['last_updated']}:** {current_date}

---

## {t['introduction']}

{t['welcome_text']} ("{business_name.lower()}", "‡§π‡§Æ", "‡§π‡§Æ‡§æ‡§∞‡§æ", ‡§Ø‡§æ "‡§π‡§Æ‡§æ‡§∞‡•á"). ‡§Ø‡§π ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§¨‡§§‡§æ‡§§‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§π‡§Æ ‡§ï‡•à‡§∏‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï‡§§‡•ç‡§∞, ‡§â‡§™‡§Ø‡•ã‡§ó, ‡§™‡•ç‡§∞‡§ï‡§ü‡•Ä‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§¨ ‡§Ü‡§™ {"‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü " + website_url + " ‡§™‡§∞ ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ " if has_online_presence else ""}‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç.

**{business_name}** ‡§è‡§ï {business_type} ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§π‡•à ‡§ú‡•ã {industry} ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à, ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á {target_audience.lower()} ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•á‡§µ‡§æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à{"" if location_country == "India" else f" ‡§î‡§∞ {location_country} ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§® ‡§ï‡•á ‡§∏‡§æ‡§•"}.

‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§∏ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•ã ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∏‡•á ‡§™‡§¢‡§º‡•á‡§Ç. ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Ø‡§æ ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡§∞‡§ï‡•á, ‡§Ü‡§™ ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§á‡§∏ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•Ä ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§¢‡§º‡§æ, ‡§∏‡§Æ‡§ù‡§æ ‡§î‡§∞ ‡§∏‡§π‡§Æ‡§§‡§ø ‡§¶‡•Ä ‡§π‡•à.

---

## {t['info_we_collect']}

### {t['personal_info']}
‡§π‡§Æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§π‡§ö‡§æ‡§® ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï‡§§‡•ç‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§Ü‡§™ ‡§∏‡•ç‡§µ‡•á‡§ö‡•ç‡§õ‡§æ ‡§∏‡•á ‡§π‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§¨ ‡§Ü‡§™:
- {"‡§ñ‡§æ‡§§‡§æ ‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç" if has_online_presence else "‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ú‡•Å‡§°‡§º‡§§‡•á ‡§π‡•à‡§Ç"}
- ‡§π‡§Æ‡§∏‡•á ‡§™‡•Ç‡§õ‡§§‡§æ‡§õ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç
- {"‡§ñ‡§∞‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§≤‡•á‡§®-‡§¶‡•á‡§® ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç" if processes_payments else "‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç"}
- ‡§π‡§Æ‡§æ‡§∞‡•á ‡§®‡•ç‡§Ø‡•Ç‡§ú‡§º‡§≤‡•á‡§ü‡§∞ ‡§Ø‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¶‡§∏‡•ç‡§Ø‡§§‡§æ ‡§≤‡•á‡§§‡•á ‡§π‡•à‡§Ç
- ‡§∏‡§∞‡•ç‡§µ‡•á‡§ï‡•ç‡§∑‡§£ ‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ö‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§§‡•á ‡§π‡•à‡§Ç

**‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞:**
- ‡§®‡§æ‡§Æ ‡§î‡§∞ ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä (‡§à‡§Æ‡•á‡§≤, ‡§´‡•ã‡§®, ‡§™‡§§‡§æ)
- {"‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§î‡§∞ ‡§¨‡§ø‡§≤‡§ø‡§Ç‡§ó ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä" if processes_payments else "‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§µ‡§ø‡§µ‡§∞‡§£"}
- {"‡§ñ‡§æ‡§§‡§æ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£-‡§™‡§§‡•ç‡§∞ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ‡§è‡§Ç" if has_online_presence else "‡§∏‡•á‡§µ‡§æ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ‡§è‡§Ç"}
- ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§î‡§∞ ‡§™‡§§‡•ç‡§∞‡§æ‡§ö‡§æ‡§∞
- {"‡§ú‡§®‡§∏‡§æ‡§Ç‡§ñ‡•ç‡§Ø‡§ø‡§ï‡•Ä‡§Ø ‡§î‡§∞ ‡§∞‡•Å‡§ö‡§ø ‡§°‡•á‡§ü‡§æ" if target_audience == "B2C" else "‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Ç"}

### ‡§ó‡•à‡§∞-‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä
‡§ú‡§¨ ‡§Ü‡§™ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§π‡§Æ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§ó‡•à‡§∞-‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï‡§§‡•ç‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç:
- {"‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞, ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä, ‡§î‡§∞ ‡§ë‡§™‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ" if has_online_presence else "‡§â‡§™‡§Ø‡•ã‡§ó ‡§™‡•à‡§ü‡§∞‡•ç‡§® ‡§î‡§∞ ‡§∏‡•á‡§µ‡§æ ‡§á‡§Ç‡§ü‡§∞‡•à‡§ï‡•ç‡§∂‡§®"}
- {"‡§Ü‡§à‡§™‡•Ä ‡§™‡§§‡§æ ‡§î‡§∞ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•ç‡§•‡§æ‡§® ‡§°‡•á‡§ü‡§æ" if uses_cookies else "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•ç‡§•‡§æ‡§® ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä"}
- {"‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§â‡§™‡§Ø‡•ã‡§ó ‡§°‡•á‡§ü‡§æ, ‡§™‡•á‡§ú ‡§µ‡•ç‡§Ø‡•Ç‡§ú‡§º, ‡§î‡§∞ ‡§®‡•á‡§µ‡§ø‡§ó‡•á‡§∂‡§® ‡§™‡•à‡§ü‡§∞‡•ç‡§®" if has_online_presence and uses_cookies else "‡§∏‡•á‡§µ‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Ü‡§Ç‡§ï‡§°‡§º‡•á"}
- {"‡§ï‡•Å‡§ï‡•Ä‡§ú‡§º ‡§î‡§∞ ‡§ü‡•ç‡§∞‡•à‡§ï‡§ø‡§Ç‡§ó ‡§§‡§ï‡§®‡•Ä‡§ï ‡§°‡•á‡§ü‡§æ" if uses_cookies else "‡§Ö‡§ú‡•ç‡§û‡§æ‡§§ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£"}

---

## {t['how_we_use']}

‡§π‡§Æ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡•à‡§ß ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§™‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç:

### ‡§∏‡•á‡§µ‡§æ ‡§µ‡§ø‡§§‡§∞‡§£
- ‡§π‡§Æ‡§æ‡§∞‡•Ä {business_type} ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§µ‡§ß‡§æ‡§® ‡§î‡§∞ ‡§∞‡§ñ‡§∞‡§ñ‡§æ‡§µ
- {"‡§≤‡•á‡§®-‡§¶‡•á‡§® ‡§î‡§∞ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ" if processes_payments else "‡§∏‡•á‡§µ‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ"}
- {"‡§Ü‡§™‡§ï‡•á ‡§ñ‡§æ‡§§‡•á ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®" if has_online_presence else "‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∏‡•á‡§µ‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡§æ"}
- ‡§Ü‡§™‡§ï‡•Ä ‡§™‡•Ç‡§õ‡§§‡§æ‡§õ ‡§î‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ

### ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§®
- ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§î‡§∞ ‡§®‡§à ‡§™‡•á‡§∂‡§ï‡§∂ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ
- ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡§®‡§æ
- {"‡§Ü‡§™‡§ï‡•á ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§î‡§∞ ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂‡•ã‡§Ç ‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§¨‡§®‡§æ‡§®‡§æ" if target_audience == "B2C" else "‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ"}
- ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§î‡§∞ ‡§ß‡•ã‡§ñ‡§æ‡§ß‡§°‡§º‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ï‡§®‡§æ

---

## {t['data_security']}

‡§π‡§Æ ‡§Ü‡§™‡§ï‡•Ä ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó-‡§Æ‡§æ‡§®‡§ï ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§â‡§™‡§æ‡§Ø ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç:

### ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§â‡§™‡§æ‡§Ø
- {"‡§°‡•á‡§ü‡§æ ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§Æ‡§ø‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è SSL/TLS ‡§è‡§®‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§®" if has_online_presence else "‡§°‡•á‡§ü‡§æ ‡§∏‡•ç‡§ü‡•ã‡§∞‡•á‡§ú ‡§î‡§∞ ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§Æ‡§ø‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§®‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§®"}
- ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§∏‡§∞‡•ç‡§µ‡§∞ ‡§î‡§∞ ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏
- ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ë‡§°‡§ø‡§ü ‡§î‡§∞ ‡§≠‡•á‡§¶‡•ç‡§Ø‡§§‡§æ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§®
- {"‡§ñ‡§æ‡§§‡§æ ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§´‡•à‡§ï‡•ç‡§ü‡§∞ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£" if has_online_presence else "‡§™‡§π‡•Å‡§Ç‡§ö ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£ ‡§â‡§™‡§æ‡§Ø"}

---

## ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§ß‡§æ‡§∞‡§£

‡§π‡§Æ ‡§Ü‡§™‡§ï‡•Ä ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§§‡§¨ ‡§§‡§ï ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§¨ ‡§§‡§ï ‡§ï‡§ø ‡§á‡§∏ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§â‡§≤‡•ç‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§®‡§æ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•ã, ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ **{data_retention_period} ‡§¶‡§ø‡§®** ‡§ú‡§¨ ‡§§‡§ï ‡§ï‡§ø:
- ‡§ï‡§æ‡§®‡•Ç‡§® ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§è‡§ï ‡§≤‡§Ç‡§¨‡•Ä ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£ ‡§Ö‡§µ‡§ß‡§ø ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à
- ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§π‡§ü‡§æ‡§®‡•á ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡•á
- ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§¶‡§æ‡§µ‡•ã‡§Ç ‡§Ø‡§æ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à
- {"‡§Ü‡§™ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡§æ‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç" if has_online_presence else "‡§Ü‡§™ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç"}

---

## {t['contact_info']}

‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§á‡§∏ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§Ø‡§æ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡§•‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§Ç‡§¨‡§Ç‡§ß ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§∂‡•ç‡§®, ‡§ö‡§ø‡§Ç‡§§‡§æ‡§è‡§Ç ‡§Ø‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§Æ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç:

**{business_name}**
- **‡§à‡§Æ‡•á‡§≤:** privacy@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **‡§™‡§§‡§æ:** {business_name} ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø, {location_country}
- **‡§´‡•ã‡§®:** {"‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§™‡§∞ ‡§¶‡•Ä ‡§ó‡§à ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§π‡§Æ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç" if has_online_presence else "‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•Ä ‡§ó‡§à ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç"}

{location_country}-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§ö‡§ø‡§Ç‡§§‡§æ‡§ì‡§Ç ‡§Ø‡§æ ‡§®‡§ø‡§Ø‡§æ‡§Æ‡§ï ‡§™‡•Ç‡§õ‡§§‡§æ‡§õ ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§™‡§§‡•ç‡§∞‡§æ‡§ö‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡•ç‡§•‡§æ‡§® ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç.

---

**‡§Ø‡§π ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡•Ä‡§§‡§ø ‡§≤‡§æ‡§ó‡•Ç ‡§°‡•á‡§ü‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§æ‡§®‡•Ç‡§®‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§ø‡§§ ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç {"‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§Ü‡§à‡§ü‡•Ä ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ 2000, ‡§ú‡•Ä‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ (‡§ú‡§π‡§æ‡§Ç ‡§≤‡§æ‡§ó‡•Ç ‡§π‡•ã), ‡§î‡§∞ " if location_country == "India" else ""}‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§®‡§ø‡§Ø‡§Æ {location_country} ‡§Æ‡•á‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç.**

*‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Ö‡§™‡§°‡•á‡§ü: {current_date}*"""
        
        else:  # English (default)
            return f"""# {t['privacy_policy']}

**{t['effective_date']}:** {current_date}  
**{t['last_updated']}:** {current_date}

---

## {t['introduction']}

{t['welcome_text']} ("{business_name.lower()}", "we", "us", "our"). This Privacy Policy outlines how we collect, use, disclose, and safeguard your information when you {"visit our website " + website_url + " or " if has_online_presence else ""}use our services.

**{business_name}** is a {business_type} business operating in the {industry} industry, primarily serving {target_audience.lower()} customers{"" if location_country == "India" else f" with operations in {location_country}"}.

Please read this Privacy Policy carefully. By using or accessing our services, you acknowledge that you have read, understood, and agree to be bound by the terms of this Privacy Policy.

---

## {t['info_we_collect']}

We collect information to provide better services to our users and operate our business effectively.

### {t['personal_info']}
- Name, email address, and contact information
- {"Account credentials and login information" if has_online_presence else "Service-related identification"}
- {"Payment information and billing details" if processes_payments else "Business transaction details"}
- Communication preferences and history

### Usage and Technical Information
- {"Website usage data, IP address, and browser information" if has_online_presence else "Service usage patterns and technical data"}
- {"Cookies and similar tracking technologies" if uses_cookies else "Session and preference data"}
- Device information and access logs
- Service interaction and performance data

### Business Information
- Company details and business requirements
- Service preferences and customizations
- Feedback and support communications
- {"Analytics and marketing preferences" if target_audience == "B2C" else "Business communication preferences"}

---

## {t['how_we_use']}

We use your information for the following legitimate business purposes:

### Service Delivery
- Providing and maintaining our {business_type} services
- Processing {"transactions and payments" if processes_payments else "service requests"}
- {"Managing your account and user experience" if has_online_presence else "Delivering personalized service"}
- Responding to your inquiries and support requests

### Business Operations
- Improving our services and developing new offerings
- Conducting market research and analytics
- {"Personalizing your experience and recommendations" if target_audience == "B2C" else "Customizing business solutions"}
- Ensuring security and preventing fraud

### Legal and Compliance
- Complying with applicable laws and regulations
- {"Processing payments and maintaining financial records" if processes_payments else "Maintaining business records"}
- Protecting our rights and interests
- Responding to legal requests and preventing misuse

### Communication
- Sending service-related notifications and updates
- {"Marketing communications (with your consent)" if target_audience == "B2C" else "Business communications and updates"}
- Newsletter and promotional content (with opt-out options)
- Important policy or service changes

---

## INFORMATION SHARING AND DISCLOSURE

We do not sell, rent, or trade your personal information. We may share your information in the following limited circumstances:

### Service Providers
We work with trusted third-party service providers who assist us in operating our business:
- {"Payment processors and financial institutions" if processes_payments else "Business service providers"}
- {"Cloud hosting and data storage providers" if has_online_presence else "Data storage and backup services"}
- {"Analytics and marketing service providers" if uses_cookies else "Business analytics providers"}
- Professional service providers (legal, accounting, consulting)

### Legal Requirements
We may disclose your information when required by law or to:
- Comply with legal obligations and court orders
- Protect and defend our rights and interests
- Prevent fraud and ensure platform security
- Respond to government requests and investigations

### Business Transfers
In the event of a merger, acquisition, or sale of our business, your information may be transferred to the new entity, subject to the same privacy protections.

---

## {t['data_security']}

We implement industry-standard security measures to protect your personal information:

### Technical Safeguards
- {"SSL/TLS encryption for data transmission" if has_online_presence else "Encryption for data storage and transmission"}
- Secure servers and protected databases
- Regular security audits and vulnerability assessments
- {"Multi-factor authentication for account access" if has_online_presence else "Access controls and authentication measures"}

### Organizational Safeguards
- Limited access on a need-to-know basis
- Employee training on data protection
- Clear data handling and retention policies
- Incident response and breach notification procedures

### Physical Safeguards
- Secure facilities and equipment
- {"Restricted access to servers and data centers" if has_online_presence else "Protected data storage locations"}
- Proper disposal of physical media
- Environmental controls and monitoring

---

## DATA RETENTION

We retain your personal information for as long as necessary to fulfill the purposes outlined in this Privacy Policy, typically **{data_retention_period} days** unless:
- A longer retention period is required by law
- You request deletion of your information
- The information is necessary for legal claims or compliance
- {"You maintain an active account with us" if has_online_presence else "You continue to use our services"}

---

## YOUR PRIVACY RIGHTS

Depending on your location, you may have the following rights regarding your personal information:

### Access and Portability
- Request access to your personal information
- Receive a copy of your data in a portable format
- {"Download your account information" if has_online_presence else "Request your service records"}

### Correction and Updates
- Correct inaccurate or incomplete information
- Update your contact preferences
- {"Modify your account settings" if has_online_presence else "Update your service preferences"}

### Deletion and Restriction
- Request deletion of your personal information
- Restrict certain processing activities
- {"Close your account and delete associated data" if has_online_presence else "Discontinue services and data processing"}

### Objection and Withdrawal
- Object to certain types of processing
- Withdraw consent for optional data processing
- Opt-out of marketing communications

**To exercise these rights, please contact us using the information provided below.**

---

## CHILDREN'S PRIVACY

Our services are not directed to children under the age of 13{" (or 16 in certain jurisdictions)" if location_country in ["European Union", "UK", "Germany"] else ""}. We do not knowingly collect personal information from children. If you believe we have inadvertently collected information from a child, please contact us immediately.

---

## INTERNATIONAL DATA TRANSFERS

{"If you are located outside of " + location_country + ", please note that your information may be transferred to and processed in " + location_country + " where our servers and business operations are located. We ensure appropriate safeguards are in place for such transfers." if location_country != "India" else "Your information is primarily processed within India. If international transfers are necessary, we ensure appropriate legal safeguards are in place."}

---

## UPDATES TO THIS POLICY

We may update this Privacy Policy periodically to reflect changes in our practices or legal requirements. We will notify you of material changes by:
- {"Posting updates on our website" if has_online_presence else "Sending you direct notifications"}
- Email notifications for significant changes
- {"In-app notifications" if has_online_presence else "Service communications"}

The updated policy will be effective immediately upon posting, and your continued use of our services constitutes acceptance of the revised terms.

---

## {t['contact_info']}

If you have questions, concerns, or requests regarding this Privacy Policy or our data practices, please contact us:

**{business_name}**
- **Email:** privacy@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name} Privacy Office, {location_country}
- **Phone:** {"Contact us through the information provided on our website" if has_online_presence else "Contact through provided business information"}

For {location_country}-specific privacy concerns or regulatory inquiries, please include your location in your correspondence.

---

**This Privacy Policy is compliant with applicable data protection laws including {"the Indian IT Act 2000, GDPR (where applicable), and " if location_country == "India" else ""}relevant privacy regulations in {location_country}.**

*Last reviewed and updated: {current_date}*"""

    elif policy_type == 'terms_conditions':
        if language == 'hi':  # Hindi
            return f"""# ‡§®‡§ø‡§Ø‡§Æ ‡§î‡§∞ ‡§∂‡§∞‡•ç‡§§‡•á‡§Ç

**{t['effective_date']}:** {current_date}  
**{t['last_updated']}:** {current_date}

---

## ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§‡§ø

**{business_name}** ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à. ‡§Ø‡•á ‡§®‡§ø‡§Ø‡§Æ ‡§î‡§∞ ‡§∂‡§∞‡•ç‡§§‡•á‡§Ç ("‡§∂‡§∞‡•ç‡§§‡•á‡§Ç") ‡§π‡§Æ‡§æ‡§∞‡•Ä {business_type} ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç {"‡§î‡§∞ ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü " + website_url if has_online_presence else "‡§î‡§∞ ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç"} ‡§ï‡•á ‡§Ü‡§™‡§ï‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç. ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Ø‡§æ ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡§∞‡§ï‡•á, ‡§Ü‡§™ ‡§á‡§® ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§∏‡•á ‡§¨‡§Ç‡§ß‡•á ‡§π‡•ã‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§π‡§Æ‡§§ ‡§π‡•à‡§Ç.

‡§Ø‡§¶‡§ø ‡§Ü‡§™ ‡§á‡§® ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§∏‡•á ‡§∏‡§π‡§Æ‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§® ‡§ï‡§∞‡•á‡§Ç.

---

## ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£

**{business_name}** ‡§è‡§ï {business_type} ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§π‡•à ‡§ú‡•ã {industry} ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à. ‡§π‡§Æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç:

{"### ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç" + chr(10) + "- ‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§™‡§π‡•Å‡§Ç‡§ö ‡§î‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ" + chr(10) + "- ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ñ‡§æ‡§§‡§æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®" + chr(10) + "- ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®" if has_online_presence else "### ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç"}
- {industry.title()} ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡§§‡§æ
- {"‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§≤‡•á‡§®-‡§¶‡•á‡§® ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç" if processes_payments else "‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§î‡§∞ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç"}
- ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§î‡§∞ ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ
- {"‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®" if target_audience == "B2B" else "‡§â‡§™‡§≠‡•ã‡§ï‡•ç‡§§‡§æ-‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç"}

---

## ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ú‡§ø‡§Æ‡•ç‡§Æ‡•á‡§¶‡§æ‡§∞‡§ø‡§Ø‡§æ‡§Ç

### ‡§ñ‡§æ‡§§‡§æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®
{"- ‡§∏‡§ü‡•Ä‡§ï ‡§ñ‡§æ‡§§‡§æ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡•á‡§Ç" + chr(10) + "- ‡§Ö‡§™‡§®‡•á ‡§≤‡•â‡§ó‡§ø‡§® ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£-‡§™‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç" + chr(10) + "- ‡§Ö‡§®‡§ß‡§ø‡§ï‡•É‡§§ ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡§Æ‡•á‡§Ç ‡§∏‡•Ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç" if has_online_presence else "- ‡§∏‡§ü‡•Ä‡§ï ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç" + chr(10) + "- ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§ü‡•Ä‡§Æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡•á‡§Ç"}
- ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§æ‡§®‡•Ç‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§®‡§ø‡§Ø‡§Æ‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡•á‡§Ç
- ‡§ï‡•á‡§µ‡§≤ ‡§µ‡•à‡§ß ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç

### ‡§®‡§ø‡§∑‡§ø‡§¶‡•ç‡§ß ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡§æ‡§Ç
‡§Ü‡§™ ‡§∏‡§π‡§Æ‡§§ ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á:
- {"‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§® ‡§ï‡§æ ‡§â‡§≤‡•ç‡§≤‡§Ç‡§ò‡§® ‡§Ø‡§æ ‡§¶‡•Ç‡§∏‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§π‡§®‡§®" + chr(10) + "- ‡§¶‡•Å‡§∞‡•ç‡§≠‡§æ‡§µ‡§®‡§æ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§Ø‡§æ ‡§∏‡•ç‡§™‡•à‡§Æ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡§æ" if has_online_presence else "‡§ß‡•ã‡§ñ‡§æ‡§ß‡§°‡§º‡•Ä ‡§Ø‡§æ ‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï ‡§™‡•ç‡§∞‡§•‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§≤‡§ó‡•ç‡§® ‡§π‡•ã‡§®‡§æ"}
- ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§Ø‡§æ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§π‡§∏‡•ç‡§§‡§ï‡•ç‡§∑‡•á‡§™ ‡§ï‡§∞‡§®‡§æ
- {"‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡•â‡§´‡§º‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•ã ‡§∞‡§ø‡§µ‡§∞‡•ç‡§∏ ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§ï‡§∞‡§®‡§æ ‡§Ø‡§æ ‡§ï‡•â‡§™‡•Ä ‡§ï‡§∞‡§®‡§æ" if has_online_presence else "‡§Æ‡§æ‡§≤‡§ø‡§ï‡§æ‡§®‡§æ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§¶‡•Å‡§∞‡•Å‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ"}
- {"‡§¶‡•Ç‡§∏‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ñ‡§æ‡§§‡§æ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£-‡§™‡§§‡•ç‡§∞ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡§æ" if has_online_presence else "‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡§Æ‡§ù‡•å‡§§‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§≤‡•ç‡§≤‡§Ç‡§ò‡§® ‡§ï‡§∞‡§®‡§æ"}

---

## ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§∂‡§∞‡•ç‡§§‡•á‡§Ç

{"### ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§î‡§∞ ‡§¨‡§ø‡§≤‡§ø‡§Ç‡§ó" + chr(10) + "- ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§ñ‡§∞‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§ø‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç" + chr(10) + "- ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç" + chr(10) + "- ‡§∏‡§≠‡•Ä ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§π‡•à‡§Ç ‡§ú‡§¨ ‡§§‡§ï ‡§ï‡§ø ‡§Ö‡§®‡•ç‡§Ø‡§•‡§æ ‡§® ‡§ï‡§π‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•ã" + chr(10) + chr(10) + "### ‡§∞‡§ø‡§´‡§Ç‡§° ‡§®‡•Ä‡§§‡§ø" + chr(10) + "- ‡§∞‡§ø‡§´‡§Ç‡§° ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§Ö‡§≤‡§ó ‡§∞‡§ø‡§´‡§Ç‡§° ‡§®‡•Ä‡§§‡§ø ‡§ï‡•á ‡§Ö‡§ß‡•Ä‡§® ‡§π‡•à‡§Ç" + chr(10) + "- ‡§ï‡•Å‡§õ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç ‡§ó‡•à‡§∞-‡§µ‡§æ‡§™‡§∏‡•Ä ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç" + chr(10) + "- ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§è‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡§Ç" if processes_payments else "### ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï" + chr(10) + "- ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§ú‡•Å‡§°‡§º‡§æ‡§µ ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡§π‡§Æ‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç" + chr(10) + "- ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§∂‡§∞‡•ç‡§§‡•á‡§Ç ‡§∏‡•á‡§µ‡§æ ‡§∏‡§Æ‡§ù‡•å‡§§‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§π‡•à‡§Ç" + chr(10) + "- ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§≤‡§æ‡§ó‡•Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç"}

---

## {t['contact_info']}

‡§á‡§® ‡§®‡§ø‡§Ø‡§Æ‡•ã‡§Ç ‡§î‡§∞ ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è:

**{business_name}**
- **‡§à‡§Æ‡•á‡§≤:** legal@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **‡§™‡§§‡§æ:** {business_name} ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§µ‡§ø‡§≠‡§æ‡§ó, {location_country}
- {"**‡§´‡•ã‡§®:** ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß" if has_online_presence else "**‡§´‡•ã‡§®:** ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•Ä ‡§ó‡§à ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç"}

---

**‡§Ø‡•á ‡§®‡§ø‡§Ø‡§Æ {location_country} ‡§Æ‡•á‡§Ç ‡§≤‡§æ‡§ó‡•Ç ‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø‡§ø‡§ï ‡§ï‡§æ‡§®‡•Ç‡§®‡•ã‡§Ç {"‡§î‡§∞ " + industry + " ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§®‡§ø‡§Ø‡§Æ‡•ã‡§Ç" if business_type in ["services", "consulting"] else ""} ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§ø‡§§ ‡§π‡•à‡§Ç.**

*‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Ö‡§™‡§°‡•á‡§ü: {current_date}*"""

        else:  # English (default)
            return f"""# TERMS AND CONDITIONS

**Effective Date:** {current_date}  
**Last Updated:** {current_date}

---

## ACCEPTANCE OF TERMS

Welcome to **{business_name}**. These Terms and Conditions ("Terms") govern your use of our {business_type} services and {"website " + website_url if has_online_presence else "services"}. By accessing or using our services, you agree to be bound by these Terms.

If you do not agree to these Terms, please do not use our services.

---

## DESCRIPTION OF SERVICES

**{business_name}** is a {business_type} company operating in the {industry} industry. We provide:

{"### Digital Services" + chr(10) + "- Online platform access and functionality" + chr(10) + "- User account management" + chr(10) + "- Digital content and resources" if has_online_presence else "### Business Services"}
- {industry.title()} solutions and expertise
- {"Payment processing and transaction services" if processes_payments else "Consultation and professional services"}
- Customer support and technical assistance
- {"Customized business solutions" if target_audience == "B2B" else "Consumer-focused services"}

---

## USER RESPONSIBILITIES

### Account Management
{"- Maintain accurate account information" + chr(10) + "- Protect your login credentials" + chr(10) + "- Notify us of unauthorized access" if has_online_presence else "- Provide accurate contact information" + chr(10) + "- Maintain communication with our team"}
- Comply with applicable laws and regulations
- Use services only for lawful purposes

### Prohibited Activities
You agree not to:
- {"Violate any laws or infringe on others' rights" + chr(10) + "- Upload malicious content or spam" if has_online_presence else "Engage in fraudulent or deceptive practices"}
- Interfere with our services or systems
- {"Reverse engineer or copy our software" if has_online_presence else "Misuse proprietary information"}
- {"Share account credentials with others" if has_online_presence else "Violate confidentiality agreements"}

---

## PAYMENT TERMS

{"### Fees and Billing" + chr(10) + "- Service fees are clearly displayed before purchase" + chr(10) + "- Payments are processed securely through authorized providers" + chr(10) + "- All fees are exclusive of applicable taxes unless stated otherwise" + chr(10) + chr(10) + "### Refund Policy" + chr(10) + "- Refunds are subject to our separate Refund Policy" + chr(10) + "- Certain services may be non-refundable" + chr(10) + "- Dispute resolution procedures are available" if processes_payments else "### Service Fees" + chr(10) + "- Service fees are agreed upon before engagement" + chr(10) + "- Payment terms are specified in service agreements" + chr(10) + "- Late payment fees may apply as specified"}

---

## CONTACT INFORMATION

For questions about these Terms and Conditions:

**{business_name}**
- **Email:** legal@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name} Legal Department, {location_country}
- {"**Phone:** Available through our website contact information" if has_online_presence else "**Phone:** Contact through provided business information"}

---

**These Terms are compliant with applicable commercial laws in {location_country} {"and industry-specific regulations for " + industry + " businesses" if business_type in ["services", "consulting"] else ""}.**

*Last reviewed and updated: {current_date}*"""

## PAYMENT TERMS

{"### Fees and Billing" + chr(10) + "- Service fees are clearly displayed before purchase" + chr(10) + "- Payments are processed securely through authorized providers" + chr(10) + "- All fees are exclusive of applicable taxes unless stated otherwise" + chr(10) + chr(10) + "### Refund Policy" + chr(10) + "- Refunds are subject to our separate Refund Policy" + chr(10) + "- Certain services may be non-refundable" + chr(10) + "- Dispute resolution procedures are available" if processes_payments else "### Service Fees" + chr(10) + "- Service fees are agreed upon before engagement" + chr(10) + "- Payment terms are specified in service agreements" + chr(10) + "- Late payment fees may apply as specified"}

---

## INTELLECTUAL PROPERTY

### Our Rights
- All content, trademarks, and intellectual property remain our property
- {"Website design, software, and digital content are protected" if has_online_presence else "Service methodologies and proprietary processes are protected"}
- You receive a limited license to use our services as intended

### Your Rights
- You retain ownership of content you provide to us
- We may use your content to provide services as agreed
- You grant us necessary licenses to deliver our services

---

## PRIVACY AND DATA PROTECTION

Your privacy is important to us. Our data practices are governed by our Privacy Policy, which is incorporated into these Terms by reference. Key points:

- We collect and process information as described in our Privacy Policy
- {"We use cookies and tracking technologies with your consent" if uses_cookies else "We collect minimal necessary information for service delivery"}
- {"We implement security measures to protect your data" if has_online_presence else "We maintain confidentiality of your business information"}
- You have rights regarding your personal information

---

## DISCLAIMERS AND LIMITATIONS

### Service Availability
- Services are provided "as is" without warranties
- {"We do not guarantee uninterrupted website availability" if has_online_presence else "We strive to provide reliable service delivery"}
- Maintenance and updates may temporarily affect service access

### Limitation of Liability
TO THE MAXIMUM EXTENT PERMITTED BY LAW:
- Our liability is limited to the amount paid for services
- We are not liable for indirect, incidental, or consequential damages
- {"Force majeure events may affect service delivery" if business_type in ["manufacturing", "retail"] else "External factors beyond our control may impact services"}

---

## DISPUTE RESOLUTION

### Governing Law
These Terms are governed by the laws of {location_country}.

### Resolution Process
1. **Direct Communication:** Contact us first to resolve issues
2. **Mediation:** Participate in good faith mediation if needed
3. **Arbitration:** {"Binding arbitration for unresolved disputes" if location_country == "India" else "Legal proceedings in appropriate jurisdiction"}

### Exceptions
Certain disputes may be resolved in small claims court or through regulatory processes.

---

## TERMINATION

### Your Right to Terminate
- {"You may close your account at any time" if has_online_presence else "You may discontinue services with appropriate notice"}
- {"Download your data before account closure" if has_online_presence else "Request your records before service termination"}

### Our Right to Terminate
We may suspend or terminate your access if you:
- Violate these Terms or our policies
- {"Engage in prohibited activities" if has_online_presence else "Breach service agreements"}
- {"Fail to pay applicable fees" if processes_payments else "Violate professional conduct standards"}

---

## MODIFICATIONS

We may update these Terms periodically. Changes will be effective:
- {"Upon posting on our website" if has_online_presence else "Upon notification to you"}
- After reasonable notice for material changes
- Immediately for legal compliance updates

Continued use of our services constitutes acceptance of updated Terms.

---

## CONTACT INFORMATION

For questions about these Terms and Conditions:

**{business_name}**
- **Email:** legal@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name} Legal Department, {location_country}
- {"**Phone:** Available through our website contact information" if has_online_presence else "**Phone:** Contact through provided business information"}

---

## ADDITIONAL PROVISIONS

### Severability
If any provision of these Terms is found unenforceable, the remaining provisions will continue in effect.

### Entire Agreement
These Terms, together with our Privacy Policy {"and any service-specific agreements" if business_type in ["services", "consulting"] else ""}, constitute the complete agreement between us.

### Assignment
We may assign these Terms in connection with a business transfer. You may not assign your rights without our consent.

---

**These Terms are compliant with applicable commercial laws in {location_country} and industry-specific regulations for {industry} businesses.**

*Last reviewed and updated: {current_date}*"""

    elif policy_type == 'refund_policy':
        return f"""# REFUND POLICY

**Effective Date:** {current_date}  
**Last Updated:** {current_date}

---

## OVERVIEW

At **{business_name}**, we are committed to customer satisfaction. This Refund Policy outlines the circumstances under which refunds may be granted for our {business_type} services {"and products" if business_type in ["retail", "e-commerce"] else ""}.

This policy applies to all {"purchases made through our website " + website_url + " and " if has_online_presence else ""}services provided by {business_name}.

---

## REFUND ELIGIBILITY

### Qualifying Circumstances
{"Refunds may be granted in the following situations:" + chr(10) + "- Service delivery failure or non-performance" + chr(10) + "- Defective products or unsatisfactory service quality" if processes_payments else "Service adjustments may be considered for:"}
- {"Technical issues preventing service access" if has_online_presence else "Service delivery issues beyond your control"}
- {"Billing errors or duplicate charges" if processes_payments else "Billing discrepancies or errors"}
- Cancellation within the specified timeframe
- {"Product returns within the return window" if business_type in ["retail", "e-commerce"] else "Service modifications before delivery"}

### Non-Refundable Services
{"Certain services and products are non-refundable:" if processes_payments else "The following circumstances typically do not qualify for refunds:"}
- {"Digital downloads after delivery" if has_online_presence else "Completed consulting services"}
- {"Customized or personalized services" if business_type in ["services", "consulting"] else "Specialized solutions"}
- {"Services used beyond the trial period" if has_online_presence else "Services substantially delivered"}
- {"Third-party fees and processing charges" if processes_payments else "External costs incurred on your behalf"}

---

## REFUND TIMEFRAMES

### Request Window
{"- Standard services: 30 days from purchase" + chr(10) + "- Digital products: 14 days from delivery" + chr(10) + "- Subscription services: According to subscription terms" if processes_payments else "- Service engagements: Within 14 days of service commencement" + chr(10) + "- Consulting services: Before substantial work begins"}
- {"Physical products: " + ("30 days from delivery" if business_type in ["retail", "e-commerce"] else "N/A") if business_type in ["retail", "e-commerce"] else "Project-based services: As specified in service agreement"}

### Processing Time
Once approved, refunds are typically processed:
- {"Credit card refunds: 5-10 business days" if processes_payments else "Service credits: Immediate application to account"}
- {"Bank transfer refunds: 3-7 business days" if processes_payments else "Cash refunds: 5-10 business days"}
- {"Digital wallet refunds: 1-3 business days" if processes_payments else "Alternative compensation: As mutually agreed"}

---

## REFUND PROCESS

### Step 1: Contact Us
- **Email:** refunds@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Include:** {"Order number, purchase date, and reason for refund" if processes_payments else "Service details, engagement date, and refund reason"}
- **Provide:** {"Screenshots or documentation if applicable" if has_online_presence else "Relevant documentation"}

### Step 2: Review Process
- We will acknowledge your request within {"24-48 hours" if has_online_presence else "2 business days"}
- {"Review of purchase records and service usage" if processes_payments else "Assessment of service delivery and satisfaction"}
- Additional information may be requested

### Step 3: Decision Notification
- Approval or denial notification within {"5-7 business days" if processes_payments else "7-10 business days"}
- Clear explanation of decision and next steps
- {"Refund processing timeline if approved" if processes_payments else "Resolution timeline if approved"}

### Step 4: Refund Processing
{"- Original payment method refund (preferred)" + chr(10) + "- Store credit or account credit (alternative)" + chr(10) + "- Bank transfer for certain payment methods" if processes_payments else "- Service credit for future engagements" + chr(10) + "- Cash refund where applicable" + chr(10) + "- Alternative compensation as agreed"}

---

## SPECIAL CIRCUMSTANCES

### Subscription Services
{"- Monthly subscriptions: Cancel anytime, no refund for current period" + chr(10) + "- Annual subscriptions: Pro-rated refund for unused months" + chr(10) + "- Free trials: No charges if canceled during trial" if has_online_presence else "- Ongoing service agreements: Refund for unused service periods" + chr(10) + "- Contract services: According to contract terms"}

### Business Services
{"- Consulting services: Refund for undelivered work only" + chr(10) + "- Custom solutions: Limited refund after work begins" + chr(10) + "- Training services: Refund before commencement only" if business_type in ["services", "consulting"] else "- Product sales: Standard return policy applies" + chr(10) + "- Service packages: Partial refunds for unused components"}

### Exceptional Circumstances
- Medical emergencies or hardship situations
- {"Technical failures beyond user control" if has_online_presence else "Service provider unavailability"}
- {"Force majeure events affecting service delivery" if business_type in ["services", "consulting"] else "External factors preventing service use"}

---

## CONDITIONS AND RESTRICTIONS

### General Conditions
{"- Products must be in original condition for returns" + chr(10) + "- Digital products must not be copied or shared" + chr(10) + "- Account must be in good standing" if business_type in ["retail", "e-commerce"] else "- Services must not be substantially utilized" + chr(10) + "- No breach of service terms" + chr(10) + "- Reasonable cause for refund request"}

### Refund Limitations
- {"Processing fees may not be refundable" if processes_payments else "Administrative costs may be deducted"}
- {"Currency conversion fees are non-refundable" if processes_payments else "Third-party costs may not be refunded"}
- Maximum refund amount is the original purchase price
- {"Multiple refund requests may be subject to review" if processes_payments else "Repeated service issues will be investigated"}

---

## DISPUTE RESOLUTION

### Internal Resolution
1. Contact our customer service team first
2. {"Escalation to management if needed" if business_type in ["services", "retail"] else "Discussion with service delivery team"}
3. {"Review by our refund committee for complex cases" if processes_payments else "Case-by-case evaluation for unique situations"}

### External Resolution
If internal resolution is unsuccessful:
- {"Dispute with payment provider (credit card company, etc.)" if processes_payments else "Professional mediation services"}
- {"Consumer protection agency complaint" if target_audience == "B2C" else "Business dispute resolution services"}
- {"Legal action as a last resort" if processes_payments else "Arbitration or legal consultation"}

---

## EXCHANGES AND STORE CREDIT

### Exchange Options
{"- Exchange for different products of equal value" + chr(10) + "- Upgrade to premium services (pay difference)" + chr(10) + "- Downgrade with partial refund" if business_type in ["retail", "e-commerce"] else "- Alternative service delivery methods" + chr(10) + "- Rescheduling of service appointments" + chr(10) + "- Modification of service scope"}

### Store Credit
{"- Credit valid for 12 months from issue date" + chr(10) + "- Can be applied to any products or services" + chr(10) + "- Non-transferable and non-refundable" if processes_payments else "- Credit applied to future service engagements" + chr(10) + "- Flexible application to different service types" + chr(10) + "- Reasonable validity period"}

---

## CONTACT INFORMATION

For refund requests and questions:

**{business_name} Customer Service**
- **Email:** refunds@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Phone:** {"Available through our website contact information" if has_online_presence else "Contact through provided business information"}
- **Address:** {business_name} Customer Service, {location_country}
- **Hours:** {"Business hours as posted on our website" if has_online_presence else "Standard business hours"}

### Escalation Contacts
- **Manager:** manager@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Legal:** legal@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}

---

## POLICY UPDATES

This Refund Policy may be updated to reflect:
- Changes in business practices
- Legal or regulatory requirements
- {"Payment processor policy updates" if processes_payments else "Industry standard updates"}
- Customer feedback and service improvements

{"Updated policies will be posted on our website with effective dates." if has_online_presence else "Updated policies will be communicated directly to customers."}

---

**This Refund Policy complies with consumer protection laws in {location_country} {"and applicable online commerce regulations" if has_online_presence else "and relevant business service standards"}.**

*Last reviewed and updated: {current_date}*"""

    elif policy_type == 'cookie_policy':
        if not uses_cookies and not has_online_presence:
            return f"""# COOKIE POLICY

**Effective Date:** {current_date}  
**Last Updated:** {current_date}

---

## NOTICE

**{business_name}** does not currently operate a website or use cookies and tracking technologies. This policy is provided for informational purposes and would apply if we implement web-based services in the future.

As a {business_type} business in the {industry} industry, we focus on direct service delivery {"and do not currently collect digital tracking data" if not collects_personal_data else "while maintaining your privacy"}.

If our operations change to include website services or digital tracking, this policy will be updated accordingly and you will be notified of any changes.

---

## CONTACT INFORMATION

For questions about our current data practices:

**{business_name}**
- **Email:** privacy@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name}, {location_country}

*Last reviewed and updated: {current_date}*"""
        
        return f"""# COOKIE POLICY

**Effective Date:** {current_date}  
**Last Updated:** {current_date}

---

## INTRODUCTION

This Cookie Policy explains how **{business_name}** ("we", "us", or "our") uses cookies and similar tracking technologies on our website {website_url} {"and related digital services" if has_online_presence else ""}.

This policy should be read alongside our Privacy Policy, which explains how we collect, use, and protect your personal information.

---

## WHAT ARE COOKIES

Cookies are small text files that are placed on your device (computer, smartphone, tablet) when you visit websites. They are widely used to make websites work more efficiently and to provide information to website owners.

### Types of Cookies We Use

#### Essential Cookies
These cookies are necessary for our website to function properly:
- **Session cookies:** Enable core website functionality
- **Security cookies:** Protect against fraud and maintain security
- **Load balancing cookies:** Ensure optimal website performance
- **Authentication cookies:** Keep you logged in to your account

#### Analytics Cookies
These help us understand how visitors use our website:
- **Google Analytics:** {"Website traffic and user behavior analysis" if has_online_presence else "Basic usage statistics"}
- **Performance monitoring:** Page load times and error tracking
- **Usage patterns:** Most popular content and navigation paths
- **Demographic data:** {"General location and device information" if target_audience == "B2C" else "Business user analytics"}

#### Functionality Cookies
These enhance your experience on our website:
- **Preference cookies:** Remember your language and region settings
- **Customization cookies:** {"Personalize content and recommendations" if target_audience == "B2C" else "Customize business interface"}
- **Shopping cart cookies:** {"Remember items in your cart" if processes_payments else "Remember service selections"}
- **Form data cookies:** Save partially completed forms

#### Marketing Cookies
{"These cookies track your browsing activity for advertising purposes:" + chr(10) + "- **Advertising networks:** Display relevant ads on other websites" + chr(10) + "- **Social media pixels:** Enable social sharing and targeted advertising" + chr(10) + "- **Retargeting cookies:** Show you relevant ads after visiting our site" + chr(10) + "- **Conversion tracking:** Measure effectiveness of marketing campaigns" if target_audience == "B2C" else "These cookies support our business marketing efforts:" + chr(10) + "- **Lead tracking:** Monitor business inquiry sources" + chr(10) + "- **Campaign analytics:** Measure marketing effectiveness" + chr(10) + "- **Professional networks:** LinkedIn and industry platform integration" + chr(10) + "- **B2B targeting:** Relevant content for business users"}

---

## HOW WE USE COOKIES

### Website Functionality
- {"Maintain your login session and preferences" if has_online_presence else "Enable core service functionality"}
- {"Process online transactions securely" if processes_payments else "Handle service requests efficiently"}
- Remember your language and location preferences
- {"Provide personalized content and recommendations" if target_audience == "B2C" else "Customize business solutions display"}

### Analytics and Performance
- Measure website traffic and user engagement
- {"Identify popular products and services" if business_type in ["retail", "e-commerce"] else "Understand service demand patterns"}
- {"Monitor website performance and loading speeds" if has_online_presence else "Track digital service performance"}
- Generate reports on website usage and effectiveness

### Marketing and Advertising
{"- Display targeted advertisements on other websites" + chr(10) + "- Measure the effectiveness of advertising campaigns" + chr(10) + "- Provide personalized content and offers" + chr(10) + "- Enable social media sharing and integration" if target_audience == "B2C" else "- Track business lead generation sources" + chr(10) + "- Measure marketing campaign effectiveness" + chr(10) + "- Customize content for business users" + chr(10) + "- Integrate with professional networking platforms"}

### Security and Fraud Prevention
- Detect and prevent fraudulent activity
- {"Secure online payment processing" if processes_payments else "Protect sensitive business information"}
- Monitor for suspicious behavior and bot traffic
- Maintain website security and integrity

---

## THIRD-PARTY COOKIES

We work with trusted third-party service providers who may set cookies on our website:

### Analytics Providers
- **Google Analytics:** {"Website traffic analysis and user insights" if has_online_presence else "Basic digital analytics"}
- **Hotjar:** {"User experience analysis and heatmaps" if has_online_presence else "Digital user experience monitoring"}

### Advertising Partners
{"- **Google Ads:** Targeted advertising and conversion tracking" + chr(10) + "- **Facebook Pixel:** Social media advertising and analytics" + chr(10) + "- **LinkedIn Insight:** Professional network advertising" if target_audience == "B2C" else "- **LinkedIn Marketing:** Business-to-business advertising" + chr(10) + "- **Google Ads:** Professional services advertising" + chr(10) + "- **Industry platforms:** Sector-specific advertising networks"}

### Payment Processors
{"- **Stripe/PayPal:** Secure payment processing cookies" + chr(10) + "- **Banking partners:** Transaction security and fraud prevention" if processes_payments else "- **Payment providers:** Secure transaction processing when applicable"}

### Communication Tools
- **Live chat services:** Customer support functionality
- {"**Email marketing:** Newsletter and communication tracking" if target_audience == "B2C" else "**Business communication:** Professional correspondence tracking"}

---

## YOUR COOKIE CHOICES

### Browser Settings
You can control cookies through your browser settings:

#### Chrome
1. Go to Settings > Privacy and security > Cookies and other site data
2. Choose your preferred cookie settings
3. {"Manage exceptions for specific websites" if has_online_presence else "Configure site-specific preferences"}

#### Firefox
1. Go to Options > Privacy & Security > Cookies and Site Data
2. Select your cookie preferences
3. {"Use custom settings for enhanced control" if has_online_presence else "Configure tracking protection"}

#### Safari
1. Go to Preferences > Privacy > Cookies and website data
2. Choose your blocking preferences
3. {"Manage website-specific settings" if has_online_presence else "Configure cross-site tracking prevention"}

#### Edge
1. Go to Settings > Site permissions > Cookies and site data
2. Configure your cookie preferences
3. {"Block or allow specific sites" if has_online_presence else "Manage site permissions"}

### Opt-Out Tools
{"- **Google Analytics Opt-out:** Use the Google Analytics opt-out browser add-on" + chr(10) + "- **Advertising opt-outs:** Visit NAI or DAA opt-out pages" + chr(10) + "- **Social media:** Adjust privacy settings on social platforms" if target_audience == "B2C" else "- **Business analytics:** Contact us for opt-out assistance" + chr(10) + "- **Professional networks:** Manage privacy settings on LinkedIn" + chr(10) + "- **Marketing communications:** Use unsubscribe links in emails"}

### Impact of Blocking Cookies
If you disable cookies, {"some website functionality may be limited:" + chr(10) + "- You may need to log in repeatedly" + chr(10) + "- Your preferences won't be saved" + chr(10) + "- Some features may not work properly" + chr(10) + "- Personalization will be reduced" if has_online_presence else "some digital services may be affected:" + chr(10) + "- Session management may be impacted" + chr(10) + "- Service preferences won't be remembered" + chr(10) + "- Some features may not function optimally"}

---

## MOBILE APPS AND DEVICES

{"If we develop mobile applications, they may use similar tracking technologies:" + chr(10) + "- **Device identifiers:** For app functionality and analytics" + chr(10) + "- **Push notification tokens:** For communication" + chr(10) + "- **Location data:** If relevant to services (with permission)" + chr(10) + "- **App usage analytics:** To improve functionality" if has_online_presence else "Our digital services may include mobile-optimized interfaces:" + chr(10) + "- **Mobile web cookies:** Similar to desktop cookie usage" + chr(10) + "- **Device-adaptive content:** Optimized for mobile devices" + chr(10) + "- **Mobile analytics:** Understanding mobile user patterns"}

---

## INTERNATIONAL TRANSFERS

{"Cookie data may be processed in different countries where our service providers operate. We ensure appropriate safeguards are in place for international data transfers, in compliance with " + location_country + " privacy laws." if location_country != "United States" else "Cookie data is primarily processed within the United States, with appropriate protections for international visitors."}

---

## UPDATES TO THIS POLICY

We may update this Cookie Policy to reflect:
- Changes in cookie usage or technologies
- New third-party partnerships
- Legal or regulatory requirements
- User feedback and privacy best practices

{"Updated policies will be posted on our website with clear notification of changes." if has_online_presence else "Updated policies will be communicated to users of our digital services."}

---

## CONTACT INFORMATION

For questions about our cookie practices:

**{business_name} Privacy Team**
- **Email:** privacy@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name} Privacy Office, {location_country}
- {"**Online form:** Available through our website contact page" if has_online_presence else "**Phone:** Contact through provided business information"}

### Data Protection Officer
{"For EU/UK residents or complex privacy questions:" + chr(10) + "- **Email:** dpo@" + website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0] if location_country in ["European Union", "UK", "Germany"] else "For privacy-related concerns:" + chr(10) + "- **Email:** privacy@" + website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}

---

## CONSENT MANAGEMENT

{"We use a cookie consent management system that allows you to:" + chr(10) + "- Accept or reject different types of cookies" + chr(10) + "- Change your preferences at any time" + chr(10) + "- Access detailed information about each cookie category" + chr(10) + "- Contact us with questions about cookie usage" if has_online_presence else "We obtain consent for cookie usage through:" + chr(10) + "- Clear notice when you first visit our digital services" + chr(10) + "- Options to manage your preferences" + chr(10) + "- Ongoing ability to change your settings" + chr(10) + "- Transparent information about cookie purposes"}

**Your continued use of our {"website" if has_online_presence else "digital services"} after accepting this policy indicates your consent to our cookie usage as described above.**

---

**This Cookie Policy complies with applicable privacy laws including {"GDPR, " if location_country in ["European Union", "UK", "Germany"] else ""}ePrivacy directives, {"and " + location_country + " digital privacy regulations" if location_country != "United States" else "and US privacy legislation"}.**

*Last reviewed and updated: {current_date}*"""

    else:
        return f"""# {policy_type.replace('_', ' ').title()}

**Effective Date:** {current_date}  
**Last Updated:** {current_date}

---

## POLICY DOCUMENT

This {policy_type.replace('_', ' ').title()} for **{business_name}** is currently being developed. 

As a {business_type} business operating in the {industry} industry{"" if location_country == "India" else f" with operations in {location_country}"}, we are committed to maintaining comprehensive legal documentation.

This document will be updated with detailed policy content specific to your business requirements and applicable legal standards.

---

## CONTACT INFORMATION

For questions about this policy:

**{business_name}**
- **Email:** legal@{website_url.replace('www.', '').replace('http://', '').replace('https://', '').split('/')[0]}
- **Address:** {business_name}, {location_country}

*Policy under development - Last updated: {current_date}*"""
    
    # Fallback for unsupported policy types
    return f"Policy type '{policy_type}' is not supported."

@app.post("/generate-policies")
async def generate_policies(payload: dict, current_user: str = Depends(get_current_user)):
    """Generate policy documents based on provided business details and requested policy types.
    Saves generated policies to Supabase and returns them to the frontend.
    Expected payload: { business_details: {...}, policy_types: [..], language: 'en' }
    """
    try:
        business = payload.get("business_details", {})
        policy_types = payload.get("policy_types", [])
        language = payload.get("language", "en")
        if not business or not policy_types:
            raise HTTPException(status_code=400, detail="business_details and policy_types are required")

        print(f"üìù Generating {len(policy_types)} policies for user {current_user}")
        
        policies = {}
        saved_policy_ids = []
        
        # Generate and save each policy
        for policy_type in policy_types:
            try:
                # Generate policy content
                policy_content = generate_policy_content(policy_type, business, language)
                policies[policy_type] = policy_content
                
                # Prepare policy data for Supabase
                business_name = business.get('business_name', 'Unknown Business')
                location_country = business.get('location_country', 'India')
                
                # Determine compliance regions based on business location
                compliance_regions = ['Indian_IT_Act']  # Default for India
                if location_country in ['European Union', 'Germany', 'France', 'UK']:
                    compliance_regions.append('GDPR')
                elif location_country == 'United States':
                    compliance_regions.extend(['CCPA', 'COPPA'])
                elif location_country == 'Canada':
                    compliance_regions.append('PIPEDA')
                
                policy_data = {
                    'user_id': int(current_user),
                    'business_name': business_name,
                    'policy_type': policy_type,
                    'content': policy_content,
                    'language': language,
                    'compliance_regions': compliance_regions
                }
                
                print(f"üíæ Saving {policy_type} policy to Supabase for {business_name}")
                
                # Insert policy into Supabase
                result = supabase.table('policies').insert(policy_data).execute()
                
                if result.data:
                    policy_id = result.data[0]['id']
                    saved_policy_ids.append(policy_id)
                    print(f"‚úÖ Successfully saved {policy_type} policy with ID: {policy_id}")
                else:
                    print(f"‚ö†Ô∏è Warning: No data returned when saving {policy_type} policy")
                    
            except Exception as policy_error:
                print(f"‚ùå Error processing {policy_type} policy: {policy_error}")
                # Continue with other policies even if one fails
                continue
        
        print(f"‚úÖ Successfully generated and saved {len(saved_policy_ids)} policies")
        
        return {
            "success": True, 
            "policies": policies,
            "saved_policy_ids": saved_policy_ids,
            "total_saved": len(saved_policy_ids)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error generating policies: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to generate policies: {str(e)}")

@app.get("/get-policies") 
async def get_policies(current_user: str = Depends(get_current_user)):
    """Get generated policies for the current user from Supabase"""
    try:
        print(f"üìã Fetching policies for user: {current_user}")
        
        # Query policies table for the current user, ordered by most recent first
        result = supabase.table('policies').select(
            'id, business_name, policy_type, content, language, compliance_regions, generated_at, updated_at'
        ).eq('user_id', int(current_user)).order('generated_at', desc=True).execute()
        
        if not result.data:
            print(f"‚ÑπÔ∏è No policies found for user {current_user}")
            return {"success": True, "data": [], "total_count": 0}
        
        policies_data = []
        for policy in result.data:
            # Transform the data to match frontend expectations
            formatted_policy = {
                "id": str(policy['id']),
                "policy_type": policy['policy_type'],
                "content": policy['content'],
                "generated_at": policy['generated_at'],
                "compliance_regions": policy.get('compliance_regions', []),
                "business_name": policy['business_name'],
                "language": policy.get('language', 'en')
            }
            policies_data.append(formatted_policy)
        
        print(f"‚úÖ Retrieved {len(policies_data)} policies from Supabase")
        
        return {
            "success": True, 
            "data": policies_data,
            "total_count": len(policies_data)
        }
        
    except Exception as e:
        print(f"‚ùå Error fetching policies from Supabase: {e}")
        # Return empty array instead of failing completely
        return {
            "success": False, 
            "data": [],
            "total_count": 0,
            "error": f"Failed to fetch policies: {str(e)}"
        }

@app.delete("/delete-policy/{policy_id}")
async def delete_policy(policy_id: str, current_user: str = Depends(get_current_user)):
    """Delete a specific policy for the current user"""
    try:
        print(f"üóëÔ∏è Attempting to delete policy {policy_id} for user {current_user}")
        
        # Verify the policy belongs to the current user before deleting
        verify_result = supabase.table('policies').select('id, user_id, policy_type').eq('id', int(policy_id)).eq('user_id', int(current_user)).execute()
        
        if not verify_result.data:
            print(f"‚ùå Policy {policy_id} not found or doesn't belong to user {current_user}")
            raise HTTPException(status_code=404, detail="Policy not found or access denied")
        
        policy_info = verify_result.data[0]
        print(f"üîç Found policy: {policy_info['policy_type']} (ID: {policy_id})")
        
        # Delete the policy
        delete_result = supabase.table('policies').delete().eq('id', int(policy_id)).eq('user_id', int(current_user)).execute()
        
        if delete_result.data:
            print(f"‚úÖ Successfully deleted policy {policy_id}")
            return {
                "success": True,
                "message": f"Policy {policy_info['policy_type']} deleted successfully",
                "deleted_policy_id": policy_id
            }
        else:
            print(f"‚ö†Ô∏è No rows affected when deleting policy {policy_id}")
            raise HTTPException(status_code=500, detail="Failed to delete policy")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error deleting policy {policy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to delete policy: {str(e)}")

# ----------------- Insurance Hub Endpoints ----------------- #

def _calculate_risk_score(assets: Dict[str, Any], workforce_size: int, risk_concerns: List[str]) -> Dict[str, Any]:
    # Basic heuristic risk score (0-100)
    asset_total = 0
    for v in assets.values():
        try:
            asset_total += float(v) if v is not None else 0
        except (TypeError, ValueError):
            continue
    base = 40
    # Asset weighting
    if asset_total > 5_000_000:
        base += 25
    elif asset_total > 1_000_000:
        base += 18
    elif asset_total > 250_000:
        base += 12
    elif asset_total > 50_000:
        base += 6
    # Workforce
    if workforce_size:
        if workforce_size > 200:
            base += 15
        elif workforce_size > 50:
            base += 10
        elif workforce_size > 10:
            base += 5
    # Risk concerns diversity
    concern_points = min(len(set(risk_concerns)) * 3, 18)
    base += concern_points
    score = max(0, min(100, base))
    if score >= 80:
        level = "High"
    elif score >= 65:
        level = "Medium"
    elif score >= 50:
        level = "Elevated"
    else:
        level = "Low"
    # Business size classification (simplistic - could blend revenue later)
    if workforce_size is None:
        workforce_size = 0
    if workforce_size <= 10:
        business_size = "micro"
    elif workforce_size <= 50:
        business_size = "small"
    elif workforce_size <= 250:
        business_size = "medium"
    else:
        business_size = "large"
    return {"risk_score": score, "risk_level": level, "asset_total": asset_total, "business_size": business_size}

@app.post("/insurance/assess")
async def insurance_assess(req: InsuranceAssessmentRequest, current_user: str = Depends(get_current_user)):
    """Perform risk assessment and return recommended insurance templates."""
    try:
        # Fetch templates from Supabase insurance_templates table
        try:
            res = supabase.table('insurance_templates').select('*').eq('is_active', True).execute()
            templates_raw = res.data or []
            print(f"‚úÖ Loaded {len(templates_raw)} templates from Supabase")
        except Exception as e:
            error_msg = str(e)
            print(f"‚ùå Error fetching insurance templates from Supabase: {error_msg}")
            
            # Check if it's a table not found error
            if "Could not find the table" in error_msg or "insurance_templates" in error_msg:
                return {
                    "success": False,
                    "error": "insurance_templates_not_found",
                    "message": "Insurance templates table not found in Supabase",
                    "instructions": {
                        "step1": "Go to Supabase Dashboard: https://supabase.com/dashboard/project/eecbqzvcnwrkcxgwjxlt",
                        "step2": "Navigate to SQL Editor",
                        "step3": "Execute the insurance table creation script",
                        "step4": "Copy and run the SQL from supabase_schema.sql file"
                    },
                    "sql_location": "/Nexora-2/nexora/python_services/supabase_schema.sql",
                    "details": "The insurance_templates table needs to be created in your Supabase database before the Insurance Hub can function properly."
                }
            else:
                raise HTTPException(status_code=500, detail=f"Database error: {error_msg}")
        
        if not templates_raw:
            return {
                "success": False,
                "error": "no_templates",
                "message": "No insurance templates found in database",
                "instructions": {
                    "step1": "Insurance templates table exists but has no data",
                    "step2": "Run the data insertion SQL from supabase_schema.sql",
                    "step3": "This will add sample insurance policies to recommend"
                }
            }

        risk_calc = _calculate_risk_score(req.assets, req.workforce_size or 0, req.risk_concerns)

        recommended = []
        for tpl in templates_raw:
            # Filter by business type
            tpl_business_types = tpl.get('business_types') or []
            if req.business_type not in tpl_business_types:
                continue
            # Risk concern intersection
            tpl_risks = set(tpl.get('risk_categories') or [])
            if req.risk_concerns and not (tpl_risks.intersection(req.risk_concerns)):
                # allow partial - skip strict filter; comment to enforce
                pass
            # Estimate coverage based on asset_total proportion
            min_cov = float(tpl.get('min_coverage_amount') or 0)
            max_cov = float(tpl.get('max_coverage_amount') or min_cov)
            asset_total = risk_calc['asset_total']
            if max_cov > min_cov:
                # linear scale
                coverage_est = min_cov + (min(1.0, asset_total / (max_cov * 1.2)) * (max_cov - min_cov))
            else:
                coverage_est = min_cov
            # Premium estimate
            base_premium = float(tpl.get('base_premium') or 0)
            risk_multiplier = 1 + (risk_calc['risk_score'] / 200)  # up to +50%
            premium_est = round(base_premium * risk_multiplier, 2)
            premium_range = f"‚Çπ{int(premium_est*0.9)} - ‚Çπ{int(premium_est*1.2)}"
            risk_match_set = tpl_risks.intersection(req.risk_concerns)
            # Scoring heuristic
            match_score = (
                (len(risk_match_set) * 10) +              # risk alignment
                (15 if req.business_type in tpl_business_types else 0) +
                (5 if risk_calc['business_size'] in ['small','medium'] else 0) +
                (3 if (req.preferences or {}).get('focus') in tpl_risks else 0)
            )
            reason_parts = []
            if risk_match_set:
                reason_parts.append(f"covers key risks: {', '.join(sorted(risk_match_set))}")
            else:
                reason_parts.append("broad foundational cover relevant to your sector")
            reason_parts.append(f"scaled coverage ‚âà ‚Çπ{int(coverage_est):,}")
            reason_parts.append(f"risk score {risk_calc['risk_score']} ({risk_calc['risk_level']})")
            reason_parts.append(f"business size {risk_calc['business_size']}")
            recommended.append({
                "template_id": tpl.get('template_id'),
                "policy_name": tpl.get('policy_name'),
                "policy_type": tpl.get('policy_type'),
                "provider_name": tpl.get('provider_name'),
                "estimated_coverage_amount": round(coverage_est, 2),
                "coverage_range": f"‚Çπ{int(min_cov)} - ‚Çπ{int(max_cov)}",
                "premium_estimate": premium_est,
                "premium_range": premium_range,
                "legal_compliance": tpl.get('legal_compliance', True),
                "compliance_authority": tpl.get('compliance_authority', 'IRDAI'),
                "compliance_badge": ("‚úÖ IRDAI Approved" if tpl.get('legal_compliance') else "‚ö†Ô∏è Review Required"),
                "coverage_details": tpl.get('coverage_description'),
                "exclusions": tpl.get('exclusions_description'),
                "optional_addons": tpl.get('optional_addons'),
                "risk_match": list(risk_match_set),
                "match_score": match_score,
                "reason": "; ".join(reason_parts)
            })

        # Guarantee at least one recommendation (fallback if filtering yields none)
        if not recommended and templates_raw:
            fallback = templates_raw[:1]
            for tpl in fallback:
                min_cov = float(tpl.get('min_coverage_amount') or 0)
                max_cov = float(tpl.get('max_coverage_amount') or min_cov)
                base_premium = float(tpl.get('base_premium') or 0)
                premium_est = round(base_premium * 1.1, 2)
                recommended.append({
                    "template_id": tpl.get('template_id'),
                    "policy_name": tpl.get('policy_name'),
                    "policy_type": tpl.get('policy_type'),
                    "provider_name": tpl.get('provider_name'),
                    "estimated_coverage_amount": min_cov,
                    "coverage_range": f"‚Çπ{int(min_cov)} - ‚Çπ{int(max_cov)}",
                    "premium_estimate": premium_est,
                    "premium_range": f"‚Çπ{int(premium_est*0.9)} - ‚Çπ{int(premium_est*1.2)}",
                    "legal_compliance": tpl.get('legal_compliance', True),
                    "compliance_authority": tpl.get('compliance_authority', 'IRDAI'),
                    "compliance_badge": ("‚úÖ IRDAI Approved" if tpl.get('legal_compliance') else "‚ö†Ô∏è Review Required"),
                    "coverage_details": tpl.get('coverage_description'),
                    "exclusions": tpl.get('exclusions_description'),
                    "optional_addons": tpl.get('optional_addons'),
                    "risk_match": [],
                    "match_score": 0,
                    "reason": "Core policy offered as a baseline recommendation (no direct risk match found)."
                })

        # Sort by match_score descending
        recommended.sort(key=lambda r: r.get('match_score', 0), reverse=True)

        # Persist assessment if table exists
        assessment_id = None
        try:
            # Mark previous as not current
            supabase.table('business_risk_assessments').update({"is_current": False}).eq('user_id', int(current_user)).eq('is_current', True).execute()
            ins = supabase.table('business_risk_assessments').insert({
                'business_id': None,  # Optional: require business linkage later
                'user_id': int(current_user),
                'assessment_data': req.model_dump(),
                'risk_score': int(risk_calc['risk_score']),
                'risk_level': risk_calc['risk_level'],
                'identified_risks': req.risk_concerns,
                'recommended_policies': [r['policy_type'] for r in recommended],
                'is_current': True
            }).execute()
            if ins.data:
                assessment_id = ins.data[0].get('assessment_id')
            print(f"‚úÖ Saved assessment {assessment_id} to database")
        except Exception as e:
            print(f"‚ÑπÔ∏è Could not persist risk assessment to DB: {e}")
            # Create a simple in-memory assessment ID for tracking
            import time
            assessment_id = f"temp_{int(current_user)}_{int(time.time())}"
            print(f"‚úÖ Created temporary assessment ID: {assessment_id}")

        return {
            "success": True,
            "assessment_id": assessment_id,
            **risk_calc,
            "recommendations": recommended,
            "count": len(recommended)
        }
    except Exception as e:
        print(f"‚ùå Insurance assessment error: {e}")
        raise HTTPException(status_code=500, detail=f"Assessment failed: {str(e)}")

@app.post('/insurance/policies')
async def create_insurance_policy(payload: InsurancePolicyCreate, current_user: str = Depends(get_current_user)):
    """Store a selected / purchased insurance policy for tracking & reminders."""
    try:
        data = payload.model_dump()
        data['user_id'] = int(current_user)
        # Auto provider fallback
        if not data.get('provider_name'):
            data['provider_name'] = 'Not Specified'
        # Insert
        res = supabase.table('insurance_policies').insert(data).execute()
        if not res.data:
            raise HTTPException(status_code=500, detail="Insert failed")
        policy = res.data[0]
        # Create auto reminder 30 days prior if expiry exists
        try:
            if policy.get('expiry_date'):
                from datetime import datetime as _dt, timedelta as _td
                expiry_dt = _dt.fromisoformat(policy['expiry_date']) if isinstance(policy['expiry_date'], str) else policy['expiry_date']
                reminder_date = expiry_dt - _td(days=30)
                if reminder_date.date() > _dt.utcnow().date():
                    supabase.table('policy_reminders').insert({
                        'policy_id': policy['policy_id'],
                        'user_id': int(current_user),
                        'reminder_type': 'renewal',
                        'reminder_date': reminder_date.date().isoformat(),
                        'notification_message': f"Renewal reminder for {policy['policy_name']}"
                    }).execute()
        except Exception as e:
            print(f"‚ÑπÔ∏è Could not create reminder: {e}")
        return {"success": True, "policy": policy}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Create policy error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create policy: {str(e)}")

@app.get('/insurance/policies')
async def list_insurance_policies(current_user: str = Depends(get_current_user)):
    try:
        res = supabase.table('insurance_policies').select('*').eq('user_id', int(current_user)).order('created_at', desc=True).execute()
        policies = res.data or []
        # annotate days to expiry
        annotated = []
        for p in policies:
            expiry = p.get('expiry_date')
            days_to_expiry = None
            if expiry:
                try:
                    from datetime import datetime as _dt
                    exp_dt = _dt.fromisoformat(expiry) if isinstance(expiry, str) else expiry
                    days_to_expiry = (exp_dt.date() - _dt.utcnow().date()).days
                except Exception:
                    pass
            p['days_to_expiry'] = days_to_expiry
            p['compliance_badge'] = "‚úÖ IRDAI Approved" if p.get('legal_compliance') else "‚ö†Ô∏è Review"
            annotated.append(p)
        return {"success": True, "policies": annotated, "count": len(annotated)}
    except Exception as e:
        print(f"‚ùå List policies error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list policies: {str(e)}")

@app.get('/insurance/policies/{policy_id}')
async def get_insurance_policy(policy_id: int, current_user: str = Depends(get_current_user)):
    try:
        res = supabase.table('insurance_policies').select('*').eq('policy_id', policy_id).eq('user_id', int(current_user)).limit(1).execute()
        if not res.data:
            raise HTTPException(status_code=404, detail="Policy not found")
        p = res.data[0]
        p['compliance_badge'] = "‚úÖ IRDAI Approved" if p.get('legal_compliance') else "‚ö†Ô∏è Review"
        return {"success": True, "policy": p}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Get policy error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get policy: {str(e)}")

@app.put('/insurance/policies/{policy_id}')
async def update_insurance_policy(policy_id: int, payload: InsurancePolicyUpdate, current_user: str = Depends(get_current_user)):
    try:
        data = {k: v for k, v in payload.model_dump().items() if v is not None}
        if not data:
            raise HTTPException(status_code=400, detail="No changes provided")
        res = supabase.table('insurance_policies').update(data).eq('policy_id', policy_id).eq('user_id', int(current_user)).execute()
        if not res.data:
            raise HTTPException(status_code=404, detail="Policy not found or not updated")
        return {"success": True, "policy": res.data[0]}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Update policy error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update policy: {str(e)}")

@app.post('/insurance/policies/{policy_id}/upload-document')
async def upload_policy_document(policy_id: int, file: UploadFile = File(...), current_user: str = Depends(get_current_user)):
    try:
        # Save locally (placeholder). In production use Supabase Storage / S3.
        docs_dir = Path('policy_docs')
        docs_dir.mkdir(exist_ok=True)
        ext = file.filename.split('.')[-1]
        fname = f"policy_{policy_id}_{uuid4().hex}.{ext}"
        path = docs_dir / fname
        with path.open('wb') as f:
            shutil.copyfileobj(file.file, f)
        doc_url = f"/static/policy_docs/{fname}"  # placeholder path
        # Update record
        supabase.table('insurance_policies').update({
            'document_url': str(path),
            'document_filename': file.filename
        }).eq('policy_id', policy_id).eq('user_id', int(current_user)).execute()
        return {"success": True, "document_url": str(path), "stored_as": fname}
    except Exception as e:
        print(f"‚ùå Upload policy document error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to upload document: {str(e)}")

@app.get('/insurance/policies/compare')
async def compare_policies(ids: str, current_user: str = Depends(get_current_user)):
    try:
        id_list = [int(i) for i in ids.split(',') if i.strip().isdigit()][:10]
        if not id_list:
            raise HTTPException(status_code=400, detail="No valid ids provided")
        res = supabase.table('insurance_policies').select('*').in_('policy_id', id_list).eq('user_id', int(current_user)).execute()
        policies = res.data or []
        # Build comparison matrix
        fields = ['policy_name', 'policy_type', 'coverage_amount', 'premium_amount', 'expiry_date', 'legal_compliance']
        comparison = []
        for p in policies:
            comparison.append({f: p.get(f) for f in fields} | {"policy_id": p.get('policy_id')})
        return {"success": True, "comparison": comparison, "count": len(comparison)}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Compare policies error: {e}")
        raise HTTPException(status_code=500, detail=f"Comparison failed: {str(e)}")

@app.post('/insurance/connect-advisor')
async def connect_advisor(payload: AdvisorConnectRequest, current_user: str = Depends(get_current_user)):
    try:
        # Placeholder: just echo request; future: store or send email / queue
        ticket_id = f"ADV-{uuid4().hex[:8].upper()}"
        return {"success": True, "ticket_id": ticket_id, "message": "Advisor request received. We'll reach out soon.", "echo": payload.model_dump()}
    except Exception as e:
        print(f"‚ùå Advisor connect error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create advisor request: {str(e)}")

@app.get('/insurance/reminders')
async def list_policy_reminders(current_user: str = Depends(get_current_user)):
    """List upcoming policy renewal reminders for the user (next 120 days)."""
    try:
        from datetime import datetime as _dt, timedelta as _td
        today = _dt.utcnow().date().isoformat()
        future = (_dt.utcnow() + _td(days=120)).date().isoformat()
        res = supabase.table('policy_reminders').select('*').eq('user_id', int(current_user)).gte('reminder_date', today).lte('reminder_date', future).order('reminder_date', desc=False).execute()
        reminders = res.data or []
        return {"success": True, "reminders": reminders, "count": len(reminders)}
    except Exception as e:
        print(f"‚ùå List reminders error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list reminders: {str(e)}")

if __name__ == "__main__":
    print("üöÄ Starting Nexora Credit Score API with Supabase Database...")
    uvicorn.run("combined_api:app", host="0.0.0.0", port=8001, reload=False)
